{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b81a547",
   "metadata": {},
   "source": [
    "# Tutorial 1: Pandas Fundamentals\n",
    "\n",
    "*Building Core Data Analysis Skills*\n",
    "\n",
    "**Estimated Time: 2-2.5 hours**\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Load and explore datasets using pandas\n",
    "- Filter and manipulate data effectively\n",
    "- Create new columns and perform calculations\n",
    "- Sort and rank data\n",
    "- Work with missing values\n",
    "- Perform basic grouping and aggregation\n",
    "- Navigate pandas documentation to solve problems\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started: Understanding Pandas\n",
    "\n",
    "Pandas is built around two main data structures:\n",
    "- **Series**: A one-dimensional array with labels (like a column in a spreadsheet)\n",
    "- **DataFrame**: A two-dimensional table with rows and columns (like a spreadsheet)\n",
    "\n",
    "### Exercise 1: Your First DataFrame\n",
    "\n",
    "Let's start by creating a simple dataset about students:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5115e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary with student data\n",
    "student_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [20, 22, 19, 21, 23],\n",
    "    'major': ['Biology', 'Physics', 'Chemistry', 'Biology', 'Physics'],\n",
    "    'gpa': [3.8, 3.2, 3.9, 3.5, 3.7]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "students = pd.DataFrame(student_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048882d",
   "metadata": {},
   "source": [
    "**Documentation Reference**: [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n",
    "\n",
    "**Question**: What do you notice about how pandas displays the data? What are the numbers on the left called?\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Loading and Exploring Real Data\n",
    "\n",
    "### Exercise 2: Loading Data from a URL\n",
    "\n",
    "For practice, let's work with the Gapminder dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91973a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gapminder dataset URL\n",
    "url = 'https://raw.githubusercontent.com/kemiolamudzengi/dsci-320-datasets/main/world-data-gapminder.csv'\n",
    "\n",
    "\n",
    "# Load the data using pd.read_csv()\n",
    "# parse_dates=['year'] tells pandas to convert the 'year' column to datetime format\n",
    "# This makes it easier to work with time-based data later\n",
    "gapminder = pd.read_csv(url, parse_dates=['year'])\n",
    "\n",
    "# Display the first few rows\n",
    "# .head() shows the first 5 rows by default - this gives us a quick peek at the data structure\n",
    "print(gapminder.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be56a64",
   "metadata": {},
   "source": [
    "**What's happening here:**\n",
    "- `pd.read_csv()` reads a CSV file from a URL and creates a DataFrame\n",
    "- `parse_dates=['year']` automatically converts the year column to a datetime data type\n",
    "- `gapminder.head()` shows us the first 5 rows so we can see what our data looks like\n",
    "\n",
    "**Documentation Reference**: [pandas.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "\n",
    "**Think About It**: Why might we want to parse the 'year' column as dates? What advantages does this give us?\n",
    "\n",
    "### Exercise 3: Getting to Know Your Data\n",
    "\n",
    "The `.info()` method is incredibly useful for understanding your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .info() to get information about the gapminder dataset\n",
    "# This shows us: data types, non-null counts, memory usage\n",
    "gapminder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee930fab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**What `.info()` tells us:**\n",
    "- **Data types**: Whether columns are numbers, text, dates, etc.\n",
    "- **Non-null count**: How many values are NOT missing in each column\n",
    "- **Memory usage**: How much space the dataset takes up\n",
    "- **Index information**: The range of row numbers\n",
    "\n",
    "**Try These Too**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the shape of the dataset (rows, columns)\n",
    "# .shape is a property (no parentheses) that returns a tuple: (rows, columns)\n",
    "print(\"Dataset shape:\", gapminder.shape)\n",
    "\n",
    "# Get the column names as a list\n",
    "# .columns gives us an Index object, .tolist() converts it to a regular Python list\n",
    "print(\"Columns:\", gapminder.columns.tolist())\n",
    "\n",
    "# Get basic statistics for numerical columns\n",
    "# .describe() automatically calculates count, mean, std, min, quartiles, max\n",
    "print(gapminder.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68668fc6",
   "metadata": {},
   "source": [
    "**What each method shows:**\n",
    "- `.shape`: Gives us (number_of_rows, number_of_columns) as a tuple\n",
    "- `.columns.tolist()`: Shows all column names in a readable list format\n",
    "- `.describe()`: Provides statistical summary for numerical columns only\n",
    "\n",
    "**Documentation References**: \n",
    "- [DataFrame.info](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\n",
    "- [DataFrame.describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)\n",
    "\n",
    "**Reflection**: Look at the output of `.info()`. How many countries are in the dataset? Which columns have missing values?\n",
    "\n",
    "---\n",
    "\n",
    "## Section 2: Selecting and Filtering Data\n",
    "\n",
    "### Exercise 4: Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the 'country' column (returns a Series)\n",
    "countries = gapminder['country']\n",
    "print(type(countries))\n",
    "\n",
    "# Select multiple columns (returns a DataFrame)\n",
    "subset = gapminder[['country', 'year', 'life_expectancy']]\n",
    "print(type(subset))\n",
    "\n",
    "# Display the first 5 rows of your subset\n",
    "print(subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ffb481",
   "metadata": {},
   "source": [
    "**Key Insight**: Single brackets `[]` return a Series, double brackets `[[]]` return a DataFrame.\n",
    "\n",
    "### Exercise 5: Filtering Rows with Boolean Indexing\n",
    "\n",
    "Boolean indexing is one of pandas' most powerful features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for data from the year 1982\n",
    "# This creates a boolean mask: True for rows where year equals '1982', False otherwise\n",
    "# Then pandas returns only the True rows\n",
    "gm_1982 = gapminder[gapminder['year'] == '1982']\n",
    "print(\"Rows in 1982:\", len(gm_1982))\n",
    "\n",
    "# Filter for countries with life expectancy greater than 75\n",
    "# The > operator creates another boolean mask\n",
    "high_life_exp = gapminder[gapminder['life_expectancy'] > 75]\n",
    "print(\"Countries with high life expectancy:\", len(high_life_exp))\n",
    "\n",
    "# Combine conditions: Countries in 1982 with life expectancy > 75\n",
    "# & means \"and\" - both conditions must be True\n",
    "# IMPORTANT: Use parentheses around each condition when combining!\n",
    "combined_filter = gapminder[\n",
    "    (gapminder['year'] == '1982') & \n",
    "    (gapminder['life_expectancy'] > 75)\n",
    "]\n",
    "print(\"High life expectancy countries in 1982:\", len(combined_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc896d",
   "metadata": {},
   "source": [
    "**How boolean indexing works:**\n",
    "1. `gapminder['year'] == '1982'` creates a Series of True/False values\n",
    "2. `gapminder[boolean_series]` returns only rows where the boolean is True\n",
    "3. `&` combines conditions with \"and\" logic (both must be True)\n",
    "4. `|` combines conditions with \"or\" logic (either can be True)\n",
    "5. **Always use parentheses** when combining conditions!\n",
    "\n",
    "**Documentation Reference**: [Boolean indexing](https://pandas.pydata.org/docs/user_guide/indexing.html#boolean-indexing)\n",
    "\n",
    "**Practice Challenge**: Filter for countries that are either in Europe OR have a life expectancy greater than 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here:\n",
    "europe_or_high_life = gapminder[\n",
    "    (gapminder['region'] == 'Europe') | \n",
    "    (gapminder['life_expectancy'] > 80)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c294d483",
   "metadata": {},
   "source": [
    "### Exercise 6: Working with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns have missing values and how many\n",
    "# .isnull() creates a DataFrame of True/False values (True = missing)\n",
    "# .sum() counts the True values (treating True as 1, False as 0)\n",
    "missing_data = gapminder.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Filter the dataset to only include rows where 'co2_per_capita' is NOT null\n",
    "# .notna() is the opposite of .isnull() - it returns True for non-missing values\n",
    "co2_data = gapminder[gapminder['co2_per_capita'].notna()]\n",
    "print(f\"Original dataset: {len(gapminder)} rows\")\n",
    "print(f\"With CO2 data: {len(co2_data)} rows\")\n",
    "\n",
    "# What years have CO2 data available?\n",
    "# .unique() returns all distinct values in a column\n",
    "available_years = co2_data['year'].unique()\n",
    "print(f\"Years with CO2 data: {len(available_years)} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a203d9",
   "metadata": {},
   "source": [
    "**Understanding missing data methods:**\n",
    "- `.isnull()`: Returns True where data is missing (NaN, None, etc.)\n",
    "- `.notna()` or `.notnull()`: Returns True where data exists\n",
    "- `.sum()` on boolean data: Counts True values (since True = 1 in math)\n",
    "- `.unique()`: Shows all distinct values, useful for checking data ranges\n",
    "\n",
    "---\n",
    "\n",
    "## Section 3: Data Manipulation and Transformation\n",
    "\n",
    "### Exercise 7: Creating New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84053922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'total_co2' by multiplying population and co2_per_capita\n",
    "# First, create a copy to avoid the SettingWithCopyWarning\n",
    "co2_data = co2_data.copy()  # This creates an independent copy of the data\n",
    "# Now we can safely add new columns\n",
    "co2_data['total_co2'] = co2_data['population'] * co2_data['co2_per_capita']\n",
    "\n",
    "print(\"New column created:\")\n",
    "print(co2_data[['country', 'year', 'population', 'co2_per_capita', 'total_co2']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e9650",
   "metadata": {},
   "source": [
    "**What's happening:**\n",
    "- `.copy()`: Creates an independent copy to avoid pandas warnings\n",
    "- `df['new_column'] = calculation`: Creates a new column using existing columns\n",
    "- Column operations are **vectorized**: the calculation applies to all rows at once\n",
    "\n",
    "### Exercise 8: Creating Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288828e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categorical column 'life_exp_category' based on life expectancy\n",
    "# np.where() works like: np.where(condition, value_if_true, value_if_false)\n",
    "# We can nest multiple np.where() calls for multiple categories\n",
    "co2_data['life_exp_category'] = np.where(\n",
    "    co2_data['life_expectancy'] < 60, 'Low',           # If < 60, assign 'Low'\n",
    "    np.where(co2_data['life_expectancy'] <= 75, 'Medium', 'High')  # Else if <= 75, 'Medium', else 'High'\n",
    ")\n",
    "\n",
    "print(\"Life expectancy categories:\")\n",
    "print(co2_data['life_exp_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dc854",
   "metadata": {},
   "source": [
    "**How np.where() works:**\n",
    "- `np.where(condition, value_if_true, value_if_false)`: Basic syntax\n",
    "- You can nest multiple `np.where()` calls for multiple categories\n",
    "- The conditions are checked in order: first condition, then second, etc.\n",
    "- `.value_counts()`: Shows how many rows fall into each category\n",
    "\n",
    "**Documentation Reference**: [numpy.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html)\n",
    "\n",
    "### Exercise 9: Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5654d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the 1982 data by life expectancy in descending order\n",
    "sorted_by_life_exp = gm_1982.sort_values('life_expectancy', ascending=False)\n",
    "print(\"Country with highest life expectancy in 1982:\")\n",
    "print(sorted_by_life_exp[['country', 'life_expectancy']].head(1))\n",
    "\n",
    "# Sort by multiple columns: first by region, then by life expectancy (descending)\n",
    "multi_sort = gm_1982.sort_values(['region', 'life_expectancy'], ascending=[True, False])\n",
    "print(\"\\nTop countries by region:\")\n",
    "print(multi_sort[['region', 'country', 'life_expectancy']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60b904",
   "metadata": {},
   "source": [
    "**Documentation Reference**: [DataFrame.sort_values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)\n",
    "\n",
    "---\n",
    "\n",
    "## Section 4: Advanced Data Operations\n",
    "\n",
    "### Exercise 10: Finding Top and Bottom Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 countries with highest CO2 per capita in the most recent year\n",
    "recent_year = co2_data['year'].max()\n",
    "recent_co2 = co2_data[co2_data['year'] == recent_year]\n",
    "\n",
    "# Find the top 10 using nlargest()\n",
    "top_10_co2 = recent_co2.nlargest(10, 'co2_per_capita')\n",
    "print(\"Top 10 CO2 emitters per capita:\")\n",
    "print(top_10_co2[['country', 'co2_per_capita']])\n",
    "\n",
    "# Find the bottom 5 countries with lowest life expectancy in 1982\n",
    "bottom_5_life_exp = gm_1982.nsmallest(5, 'life_expectancy')\n",
    "print(\"\\nCountries with lowest life expectancy in 1982:\")\n",
    "print(bottom_5_life_exp[['country', 'life_expectancy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd75c0",
   "metadata": {},
   "source": [
    "**Documentation Reference**: [DataFrame.nlargest](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html)\n",
    "\n",
    "### Exercise 11: Basic Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average life expectancy by region for 1982\n",
    "# .groupby('region') groups all rows by their region value\n",
    "# ['life_expectancy'] selects just that column from each group\n",
    "# .mean() calculates the average for each group\n",
    "regional_avg = gm_1982.groupby('region')['life_expectancy'].mean()\n",
    "print(\"Average life expectancy by region (1982):\")\n",
    "print(regional_avg.round(1))\n",
    "\n",
    "# For each region, find the count of countries and average income\n",
    "# .agg(['count', 'mean']) applies multiple functions to the grouped data\n",
    "regional_stats = gm_1982.groupby('region')['income'].agg(['count', 'mean'])\n",
    "print(\"\\nRegional income statistics:\")\n",
    "print(regional_stats.round(0))\n",
    "\n",
    "# Create a more complex aggregation\n",
    "# When you pass a dictionary to .agg(), you can apply different functions to different columns\n",
    "if 'income_group' in gm_1982.columns:\n",
    "    complex_agg = gm_1982.groupby('income_group').agg({\n",
    "        'life_expectancy': 'mean',  # Average life expectancy for each income group\n",
    "        'population': 'sum',        # Total population for each income group\n",
    "        'country': 'count'          # Number of countries in each income group\n",
    "    })\n",
    "    print(\"\\nIncome group analysis:\")\n",
    "    print(complex_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de764d71",
   "metadata": {},
   "source": [
    "**How groupby works:**\n",
    "1. **Split**: `.groupby('column')` divides data into groups based on unique values\n",
    "2. **Apply**: Functions like `.mean()`, `.sum()`, `.count()` are applied to each group\n",
    "3. **Combine**: Results are combined into a new DataFrame or Series\n",
    "4. **Multiple functions**: `.agg(['func1', 'func2'])` applies multiple functions\n",
    "5. **Different functions per column**: `.agg({'col1': 'mean', 'col2': 'sum'})` for flexibility\n",
    "\n",
    "**Documentation Reference**: [DataFrame.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
    "\n",
    "---\n",
    "\n",
    "## Section 5: Working with Time Series Data\n",
    "\n",
    "### Exercise 12: Date Operations and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year as a number from the datetime column\n",
    "gapminder['year_num'] = gapminder['year'].dt.year\n",
    "\n",
    "# Filter for data from specific years: 1952, 1977, 2002\n",
    "selected_years = ['1952', '1977', '2002']\n",
    "time_series_data = gapminder[gapminder['year'].isin(selected_years)]\n",
    "\n",
    "print(f\"Data from selected years: {len(time_series_data)} rows\")\n",
    "print(\"Years included:\")\n",
    "print(time_series_data['year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac402ddf",
   "metadata": {},
   "source": [
    "**Documentation Reference**: [pandas.DataFrame.isin](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html)\n",
    "\n",
    "---\n",
    "\n",
    "## Section 6: Using Pandas Documentation\n",
    "\n",
    "### Exercise 13: Documentation Navigation\n",
    "\n",
    "Learning to use the pandas documentation is crucial for solving new problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice finding documentation for these methods:\n",
    "# 1. How to calculate correlation between two columns\n",
    "correlation_example = gapminder[['life_expectancy', 'income']].corr()\n",
    "print(\"Correlation between life expectancy and income:\")\n",
    "print(correlation_example)\n",
    "\n",
    "# 2. How to get unique values and their counts\n",
    "unique_regions = gapminder['region'].value_counts()\n",
    "print(\"\\nCountries per region:\")\n",
    "print(unique_regions)\n",
    "\n",
    "# 3. How to calculate rolling averages (you'll need to look this up!)\n",
    "# Hint: Look for \"rolling\" in the pandas documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb35a0",
   "metadata": {},
   "source": [
    "**Key Documentation Resources:**\n",
    "1. **User Guide**: [pandas.pydata.org/docs/user_guide/](https://pandas.pydata.org/docs/user_guide/)\n",
    "2. **API Reference**: [pandas.pydata.org/docs/reference/](https://pandas.pydata.org/docs/reference/)\n",
    "3. **Search Strategy**: Use Ctrl+F to find specific method names\n",
    "\n",
    "---\n",
    "\n",
    "## Common Patterns and Best Practices\n",
    "\n",
    "### Pattern 1: Method Chaining\n",
    "Instead of creating many intermediate variables, you can chain operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc96702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain operations together for cleaner code\n",
    "result = (gapminder\n",
    "          .query('year == \"2000\"')  # Filter condition\n",
    "          [['country', 'region', 'life_expectancy']]  # Select columns\n",
    "          .sort_values('life_expectancy', ascending=False)  # Sort\n",
    "          .head(10))  # Get top 10\n",
    "\n",
    "print(\"Top 10 countries by life expectancy in 2000:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54edc51e",
   "metadata": {},
   "source": [
    "### Pattern 2: Handling the SettingWithCopyWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you modify a subset of data, use .copy()\n",
    "subset = gapminder[gapminder['year'] == '2000'].copy()\n",
    "subset['new_column'] = subset['life_expectancy'] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e2140",
   "metadata": {},
   "source": [
    "### Pattern 3: Safe Data Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always check your data after operations\n",
    "print(\"Before operation:\", gapminder.shape)\n",
    "filtered_data = gapminder[gapminder['life_expectancy'] > 50]\n",
    "print(\"After filtering:\", filtered_data.shape)\n",
    "print(\"Percentage retained:\", len(filtered_data) / len(gapminder) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7cc3c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "### Exercise 14: Putting It All Together\n",
    "\n",
    "Use everything you've learned to answer these questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac249990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Which country had the fastest improvement in life expectancy between 1952 and 2007?\n",
    "# Try doing this by yourself, using what you have learned so far. \n",
    "# The solution is at the bottom of the notebook.\n",
    "\n",
    "\n",
    "# Step 1: Get data for 1952 and 2007\n",
    "data_1952 = ...\n",
    "data_2007 = ...\n",
    "\n",
    "# Step 2: Merge the datasets to compare\n",
    "improvement_data = ...\n",
    "\n",
    "# Step 3: Calculate improvement\n",
    "improvement_data['life_exp_improvement'] = ...\n",
    "\n",
    "# Step 4: Find the country with highest improvement\n",
    "best_improvement = ...\n",
    "\n",
    "print(\"Country with fastest life expectancy improvement:\")\n",
    "print(best_improvement[['country', 'life_exp_improvement']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1345d58",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've now learned the fundamental pandas skills for data analysis:\n",
    "\n",
    "### **Core Skills Mastered:**\n",
    "1. **Loading and inspecting** data with `read_csv()`, `info()`, `describe()`\n",
    "2. **Selecting and filtering** data with boolean indexing\n",
    "3. **Creating new columns** with calculations and transformations\n",
    "4. **Sorting and ranking** data for analysis\n",
    "5. **Handling missing values** with appropriate strategies\n",
    "6. **Basic grouping and aggregating** with `groupby()`\n",
    "7. **Working with dates** and time series data\n",
    "8. **Using pandas documentation** effectively\n",
    "\n",
    "### **Key Patterns to Remember:**\n",
    "- Use `.copy()` when modifying filtered data\n",
    "- Combine conditions with `&` (and) and `|` (or) in parentheses\n",
    "- Chain methods for cleaner, more readable code\n",
    "- Always validate your data after operations\n",
    "\n",
    "### **Next Steps:**\n",
    "- Practice these techniques on different datasets\n",
    "- Explore more advanced pandas functions\n",
    "- Learn data cleaning techniques for visualization\n",
    "- Apply these skills in your assignments!\n",
    "\n",
    "**Congratulations!** You now have a solid foundation in pandas for data analysis. These skills will serve you well throughout the course and in your future data science work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a798903",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating Your Pandas Cheat Sheet\n",
    "\n",
    "As you learn pandas, it's crucial to build your own reference guide. A personalized cheat sheet helps you remember syntax and builds confidence for quizzes and projects.\n",
    "\n",
    "### **Five-Step Process for Building Your Cheat Sheet**\n",
    "\n",
    "#### **Step 1: Create Your Outline (5 minutes)**\n",
    "Set up a document (Word, Google Doc, or notebook) with these sections:\n",
    "- **Data Loading & Exploration**\n",
    "- **Data Selection & Filtering** \n",
    "- **Data Manipulation**\n",
    "- **Grouping & Aggregation**\n",
    "- **Common Patterns**\n",
    "\n",
    "#### **Step 2: Extract Key Syntax (10 minutes)**\n",
    "Go through each section of this tutorial and write down the **essential syntax**:\n",
    "\n",
    "```\n",
    "DATA LOADING & EXPLORATION:\n",
    "• pd.read_csv(url, parse_dates=['col'])\n",
    "• df.info() - data types and missing values\n",
    "• df.describe() - statistical summary\n",
    "• df.shape - (rows, columns)\n",
    "• df.columns.tolist() - column names\n",
    "\n",
    "DATA SELECTION & FILTERING:\n",
    "• df['column'] - single column (Series)\n",
    "• df[['col1', 'col2']] - multiple columns (DataFrame) \n",
    "• df[df['col'] > value] - boolean filtering\n",
    "• df[(condition1) & (condition2)] - multiple conditions\n",
    "• df['col'].isnull() / .notna() - missing value checks\n",
    "```\n",
    "\n",
    "#### **Step 3: Add Your Own Examples (10 minutes)**\n",
    "For each syntax pattern, write a **concrete example** from your own practice:\n",
    "\n",
    "```\n",
    "EXAMPLE: Filter high life expectancy countries in 2000\n",
    "high_life_2000 = gapminder[\n",
    "    (gapminder['year'] == '2000') & \n",
    "    (gapminder['life_expectancy'] > 75)\n",
    "]\n",
    "```\n",
    "\n",
    "#### **Step 4: Note Common Gotchas (5 minutes)**\n",
    "Record the mistakes you made or almost made:\n",
    "\n",
    "```\n",
    "REMEMBER:\n",
    "• Use .copy() when modifying filtered data\n",
    "• Always use parentheses with & and | operators\n",
    "• .shape is a property (no parentheses)\n",
    "• Use .tolist() to convert columns to readable list\n",
    "```\n",
    "\n",
    "#### **Step 5: Test Your Cheat Sheet (5 minutes)**\n",
    "Pick 2-3 random operations from your cheat sheet and try them on a dataset. If you can't remember how to use them, add more detail to your notes.\n",
    "\n",
    "### **Pro Tips for Effective Cheat Sheets:**\n",
    "\n",
    "1. **Keep it concise**: One page per tutorial maximum\n",
    "2. **Use your own words**: Don't just copy-paste from tutorials\n",
    "3. **Include error solutions**: Note how you fixed common mistakes\n",
    "4. **Update regularly**: Add new patterns as you encounter them\n",
    "5. **Practice from it**: Use your cheat sheet to solve new problems\n",
    "\n",
    "### **Before Your Next Tutorial:**\n",
    "Spend 35 minutes total creating your Tutorial 1A cheat sheet. \n",
    "This investment will pay off during future assignments when you need to recall syntax quickly.\n",
    "\n",
    "**Your cheat sheet is your personal pandas survival guide - make it work for you!**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51d6f2",
   "metadata": {},
   "source": [
    "## Self-Check Questions\n",
    "\n",
    "Before moving on, make sure you can answer these questions. **Practice coding the answers** to prepare for your quiz:\n",
    "\n",
    "### **Basic Concepts (Practice these first)**\n",
    "\n",
    "1. **What's the difference between selecting columns with `df['col']` vs `df[['col']]`?**\n",
    "   - Try both on a sample dataset and observe the output types\n",
    "\n",
    "2. **How do you combine multiple conditions in boolean indexing?**\n",
    "   - Practice creating filters with both `&` (and) and `|` (or)\n",
    "   - Remember: always use parentheses around each condition!\n",
    "\n",
    "3. **What's the purpose of using `.copy()` when creating filtered datasets?**\n",
    "   - When do you need it and why does pandas give warnings without it?\n",
    "   \n",
    "4. **How do you find the top N values in a column?**\n",
    "   - Pick an attribute from the dataset and make sure you can filter to only keep N values?\n",
    "\n",
    "5. **What's the basic pattern for groupby operations?**\n",
    "   \n",
    "\n",
    "### **Applied Skills (Quiz-level questions)**\n",
    "\n",
    "4. **Complex Filtering Challenge:**\n",
    "   Write code to find countries that meet ALL these conditions:\n",
    "   - Life expectancy greater than 70\n",
    "   - Population greater than 5 million\n",
    "   - From either Europe OR North America\n",
    "   \n",
    "\n",
    "5. **Groupby Analysis Challenge:**\n",
    "   For each region, calculate:\n",
    "   - The count of countries\n",
    "   - The average life expectancy\n",
    "   - The country with the highest income (hint: use `.idxmax()`)\n",
    "   \n",
    "\n",
    "6. **Missing Data Strategy Challenge:**\n",
    "   You have a dataset where:\n",
    "   - 'essential_column' has 5% missing values\n",
    "   - 'optional_column' has 40% missing values\n",
    "   - 'analysis_column' has 15% missing values\n",
    "   \n",
    "   What strategy would you use for each column and why? Practice implementing your strategy in code.\n",
    "\n",
    "**If you can confidently answer and code solutions for questions 4-7, you're well-prepared for the quiz!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Exercise 14\n",
    "\n",
    "# Step 1: Get data for 1952 and 2007\n",
    "data_1952 = gapminder[gapminder['year'] == '1952']\n",
    "data_2007 = gapminder[gapminder['year'] == '2007']\n",
    "\n",
    "# Step 2: Merge the datasets to compare\n",
    "improvement_data = data_1952.merge(\n",
    "    data_2007, \n",
    "    on='country', \n",
    "    suffixes=('_1952', '_2007')\n",
    ")\n",
    "\n",
    "# Step 3: Calculate improvement\n",
    "improvement_data['life_exp_improvement'] = (\n",
    "    improvement_data['life_expectancy_2007'] - \n",
    "    improvement_data['life_expectancy_1952']\n",
    ")\n",
    "\n",
    "# Step 4: Find the country with highest improvement\n",
    "best_improvement = improvement_data.nlargest(1, 'life_exp_improvement')\n",
    "print(\"Country with fastest life expectancy improvement:\")\n",
    "print(best_improvement[['country', 'life_exp_improvement']])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
